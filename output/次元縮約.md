# 次元縮約（次元削減・ディメンション削減）

## 概要

次元縮約（次元削減、ディメンション削減）とは、多次元データの持つ情報を、できるだけ意味を保ったまま、より少ない次元に圧縮する手法です。主に機械学習や統計解析、空間統計などで利用されます。

---

## 目的
- **データの圧縮**：計算資源の節約や高速化、大規模データの扱いやすさ向上。
- **データの可視化**：人間が理解しやすい2次元・3次元への変換。
- **多変量関係の調査**：変数間の関係性や特徴抽出。
- **機械学習アルゴリズムの計算コスト削減**：不要な次元を減らし、過学習を防ぐ。

---

## 主な手法

### 主成分分析（PCA: Principal Component Analysis）
- 元の変数の分散をできるだけ多く保持する新しい軸（主成分）を作成。
- 連続変数のセットを、より少ない成分に集約。
- データのスケール（標準化）を行うことで、各変数の重要度を均等にできる。
- 分散が大きい方向（情報量が多い方向）を優先して次元を削減。
- 射影誤差（二乗和）を最小化する方向を選ぶ。

### 線形判別分析（LDA: Linear Discriminant Analysis）
- カテゴリ変数（ラベル）の分離性を最大化する成分を構築。
- 各カテゴリ間の分散を保持し、分類性能を高める。
- 主に分類問題で利用。

---

## 実用例
- 機械学習の前処理（特徴量圧縮、ノイズ除去）
- 空間統計や地理情報システム（GIS）での多変量データ解析
- データの可視化（2次元・3次元プロット）

---

## 次元数の決定方法
- 保持したい分散の割合（例：99%）を基準に主成分数を決定
- ブロークン・スティック法やバートレットの球面性検定などの統計的手法も利用可能

---

## 注意点
- 次元削減により元データの一部情報は失われる（情報損失）
- 可視化目的の場合、厳密な数値情報は失われるが、傾向把握には有効
- 欠損値やスケールの違いに注意

---

## 参考文献・リンク
- [Qiita: 30分でわかる機械学習用語「次元削減(Dimensionality Reduction)」](https://qiita.com/aya_taka/items/4d3996b3f15aa712a54f)
- [ArcGIS Pro: ディメンションの削減 (Dimension Reduction)](https://pro.arcgis.com/ja/pro-app/latest/tool-reference/spatial-statistics/dimensionreduction.htm)
- James, G., Witten, D., Hastie, T., Tibshirani, R. (2014). "An Introduction to Statistical Learning: with Applications in R." Springer Publishing Company, Incorporated.
- Peres-Neto, P., Jackson, D., Somers, K. (2005). "How many principal components? Stopping rules for determining the number of non-trivial axes revisited." Computational Statistics & Data Analysis. 49.4: 974-997. 